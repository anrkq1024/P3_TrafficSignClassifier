{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity - SDCND Project : Implement Traffic_Sign_Classifier using LeNet of the CNN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "training_file = '/home/nsslab/Downloads/traffic-signs-data/train.p'\n",
    "validation_file='/home/nsslab/Downloads/traffic-signs-data/valid.p'\n",
    "testing_file = '/home/nsslab/Downloads/traffic-signs-data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Dataset Summary & Exploratory                           Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Summary\n",
    "- 'features' is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels)\n",
    "- 'labels' is a 1D array containing the label/class id of the traffic sign. The file signnames.csv contains id -> name mappings for each id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(X_train)\n",
    "\n",
    "n_validation = len(X_valid)\n",
    "\n",
    "n_test = len(X_test)\n",
    "\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation example \",n_validation)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Total data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image, nr, nc, i, label=\"\"):\n",
    "    \"\"\"\n",
    "    Plot a single image.\n",
    "    If 'i' is greater than 0, then plot this image as \n",
    "    a subplot of a larger plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    if i>0: \n",
    "        plt.subplot(nr, nc, i)\n",
    "    else:\n",
    "        plt.figure(figsize=(nr,nc))\n",
    "        \n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.xlabel(label)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "    \n",
    "import random\n",
    "def plot_random(dataset1, dataset2=None, instances=1):\n",
    "    \"\"\"\n",
    "    Plot a random image from one or two datasets.\n",
    "    \"\"\"\n",
    "    nc = 1 if dataset2 is None else 2\n",
    "    nr = instances\n",
    "    #plt.figure(figsize=(nr,nc))\n",
    "    for i in range(instances):\n",
    "        index = random.randint(0, len(dataset1))\n",
    "        plot_image(dataset1[index].squeeze(), nr, nc, 2*i+1)\n",
    "        if dataset2 is not None:\n",
    "            image = dataset2[index].squeeze()\n",
    "            plot_image(image, nr, nc, 2*i+2)\n",
    "            print(\"image mean=\", image.mean())\n",
    "\n",
    "\n",
    "from scipy import misc\n",
    "def get_image_per_class(X, y):\n",
    "    \"\"\" \n",
    "    Plot a representatative of each image class in a 5x10 image grid\n",
    "\n",
    "    The training dataset is traversed until a sample of each class\n",
    "    is encountered and cached.\n",
    "\n",
    "    Another loop then travereses all of the cached images and displays them.\n",
    "    The two loops are required because we want to display the image samples\n",
    "    in class order, not in the order they are encountered.\n",
    "    \"\"\"\n",
    "    signs_left = n_classes\n",
    "    class_images = [None for x in range(signs_left)]\n",
    "\n",
    "    i = 0\n",
    "    while signs_left>0:\n",
    "        if class_images[y[i]] == None:\n",
    "            image = X[i].squeeze()\n",
    "            class_images[y[i]] = image\n",
    "            signs_left -= 1\n",
    "        i += 1\n",
    "    return class_images\n",
    "\n",
    "\n",
    "def summarize_stats(class_images, y_train, y_valid):\n",
    "    \"\"\"\n",
    "    'class_images' is a list of images, one per class.\n",
    "    This function plots this images list, and print underneath each one its class, \n",
    "    the number of training samples, the percent of training samples, \n",
    "    and the percent of validation samples\n",
    "    \"\"\"\n",
    "    # Create a histogram of the classes\n",
    "    y_train_hist = np.bincount(y_train)\n",
    "    y_valid_hist = np.bincount(y_valid)\n",
    "\n",
    "    nr = 5; nc = 9\n",
    "    plt.figure(figsize=(nr,nc))\n",
    "    for image,i in zip(class_images, range(len(class_images))):\n",
    "        label = (str(i) + \"\\n\"                                            # class\n",
    "              + str(y_train_hist[i]) + \"\\n\"                               # no. of training samples\n",
    "              + \"{:.1f}%\".format(100 * y_train_hist[i]/sum(y_train_hist))  + \"\\n\"   # representation in training samples\n",
    "              + \"{:.1f}%\".format(100 * y_valid_hist[i]/sum(y_valid_hist)))     # representation in validation samples\n",
    "        plot_image(image, nr, nc, i+1, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Design and Train a Model Architecture\n",
    "## Preprocess Data\n",
    "- convert RGB images to GRAY images\n",
    "\n",
    " As shown in the figure below, Converting from rgb to gray allows the classifier to better recognize the sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_instances(img_class, y):\n",
    "    y_hist = np.bincount(y)\n",
    "    n_instances = y_hist[img_class]\n",
    "    return n_instances\n",
    "\n",
    "def get_class_images(img_class, X, y):\n",
    "    n_instances = get_num_instances(img_class, y)\n",
    "    class_images = []\n",
    "    i = 0\n",
    "    while n_instances>0:\n",
    "        if y[i] == img_class:\n",
    "            image = X[i].squeeze()\n",
    "            class_images.append(image)\n",
    "            n_instances -= 1\n",
    "        i += 1\n",
    "    return class_images\n",
    "\n",
    "import math\n",
    "def plot_class_images(img_class, class_images, ncol, desc):\n",
    "    nimages = len(class_images)\n",
    "    nrow = math.ceil(nimages/ncol)\n",
    "    #plt.figure(figsize=(nrow,ncol))\n",
    "    print(\"class {} has {} images in the {} dataset\".format(img_class,nimages, desc))\n",
    "    for image,i in zip(class_images, range(nimages)):\n",
    "        plot_image(image, nrow, ncol, i)\n",
    "    \n",
    "def plot_class(img_class, X, y, ncol, desc):\n",
    "    class_images = get_class_images(img_class, X, y)\n",
    "    plot_class_images(img_class, class_images, ncol,  desc)\n",
    "\n",
    "class_images = get_class_images(20, X_train, y_train)\n",
    "for i in range(4):\n",
    "    plot_image(class_images[i], 1, 4, i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray(x):\n",
    "    x = np.sum(x/3, axis=3, keepdims=True)\n",
    "    x = np.sum(x/3, axis=3, keepdims=True)\n",
    "    return x\n",
    "X_train = gray(X_train)\n",
    "X_valid = gray(X_valid)\n",
    "X_test  = gray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalization the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Norm(x):\n",
    "    x = x / 255\n",
    "    x -= np.mean(x)\n",
    "    x /= np.std(x)\n",
    "    return x\n",
    "\n",
    "X_train = Norm(X_train)\n",
    "X_valid = Norm(X_valid)\n",
    "X_test  = Norm(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shuffle the training data\n",
    "\n",
    " Randomly mix sequences of the data so that the sequence of the data does not affect learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "epoch = 50\n",
    "batch_size = 155\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):\n",
    "    #Set hyperparameter\n",
    "    mn = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    \"\"\"\n",
    "    #Convolutional Layer1 input : 32*32*1 output = 28*28*10\n",
    "    \"\"\"\n",
    "    conv1_w = tf.Variable(tf.truncated_normal(shape=(5 ,5 ,1 ,10), mean = mn , stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(10))\n",
    "    conv1 = tf.nn.conv2d(x, conv1_w, strides=[1, 1, 1, 1], padding = 'VALID') + conv1_b\n",
    "    \n",
    "    #Activation\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    \n",
    "    \"\"\"\n",
    "    #Max_pool Layer1 input : 28*28*10 output = 14*14*10\n",
    "    \"\"\"\n",
    "    \n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding = 'VALID')\n",
    "    \n",
    "    \"\"\"\n",
    "    #Convolutional Layer2 input : 14*14*10 output = 10*10*25\n",
    "    \"\"\"\n",
    "    \n",
    "    conv2_w = tf.Variable(tf.truncated_normal(shape=(5 ,5 ,10 ,25), mean = mn , stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(25))\n",
    "    conv2 = tf.nn.conv2d(conv1, conv2_w, strides=[1, 1, 1, 1], padding = 'VALID') + conv2_b\n",
    "    \n",
    "    #Activation\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    \"\"\"\n",
    "    #Max_pool Layer2 input : 10*10*25 output = 5*5*25\n",
    "    \"\"\"\n",
    "    \n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding = 'VALID')\n",
    "    \n",
    "    \"\"\"\n",
    "    3 #Fully connected Layer3 input = 5*5*25 = 625 output = 250\n",
    "    \"\"\"\n",
    "    \n",
    "    #Flatten input = 5*5*25 output = 625\n",
    "    f_conv0 = flatten(conv2)\n",
    "       \n",
    "    f_w1 = tf.Variable(tf.truncated_normal(shape=(625,250), mean = mn , stddev = sigma))\n",
    "    f_b1 = tf.Variable(tf.zeros(250))\n",
    "    f_conv1 = tf.matmul(f_conv0, f_w1) + f_b1\n",
    "    \n",
    "    #Activation\n",
    "    f_conv1 = tf.nn.relu(f_conv1)\n",
    "    \"\"\"\n",
    "     Apply dropout to prevent overfitting  \n",
    "     The probability that a node will be transported to the next layer is 75%\n",
    "    \"\"\"\n",
    "    \n",
    "    f_conv1 = tf.nn.dropout(f_conv1, 0.75)\n",
    "    \n",
    "    \"\"\"\n",
    "    4 #Fully connected Layer4 input = 250 output = 86\n",
    "    \"\"\"\n",
    "    \n",
    "    f_w2 = tf.Variable(tf.truncated_normal(shape=(250,86), mean = mn , stddev = sigma))\n",
    "    f_b2 = tf.Variable(tf.zeros(86))\n",
    "    f_conv2 = tf.matmul(f_conv1, f_w2) + f_b2\n",
    "    \n",
    "    #Activation\n",
    "    f_conv2 = tf.nn.relu(f_conv2)\n",
    "    \n",
    "    \"\"\"\n",
    "     Apply dropout to prevent overfitting  \n",
    "    \"\"\"\n",
    "    f_conv2 = tf.nn.dropout(f_conv2, 0.75)\n",
    "    \n",
    "    \"\"\"\n",
    "    5 #Fully connected Layer5 input = 84 output = 43\n",
    "    \"\"\"\n",
    "    \n",
    "    f_w3 = tf.Variable(tf.truncated_normal(shape=(86,43), mean = mn , stddev = sigma))\n",
    "    f_b3 = tf.Variable(tf.zeros(43))\n",
    "    \n",
    "    \"\"\"\n",
    "    Finally, proccessed values mean logits\n",
    "    \"\"\"\n",
    "    \n",
    "    #Predicted output\n",
    "    logits = tf.matmul(f_conv2, f_w3) + f_b3\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization to minimize the difference between the actual value and the predicted value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because the final size of the batch is not constant, the first element is None\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "\n",
    "one_hot_y = tf.one_hot(y,43)    \n",
    "#learning rate\n",
    "rate = 0.001\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "def evaluation(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, batch_size):\n",
    "        batch_x, batch_y = X_data[offset:offset+batch_size], y_data[offset:offset+batch_size]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict = {x:batch_x, y:batch_y})\n",
    "        total_accuracy += (accuracy*len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model and than validate&test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    save_file = './save_train.ckpt'\n",
    "    \n",
    "    validation_accuracy_graph = []\n",
    "    test_accuracy_graph = []\n",
    "    training_accuracy_graph = []\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        \n",
    "        for offset in range(0, num_examples, batch_size):\n",
    "            end = offset + batch_size\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        train_accuracy = evaluation(X_train, y_train)\n",
    "        validation_accuracy = evaluation(X_valid, y_valid)\n",
    "        test_accuracy = evaluation(X_test, y_test)       \n",
    "        \n",
    "        validation_accuracy_graph.append(validation_accuracy)\n",
    "        test_accuracy_graph.append(test_accuracy)\n",
    "        train_accuracy_graph.append(train_accuracy)\n",
    "        \n",
    "        print(\"epoch {}...\".format(i+1))\n",
    "        print(\"Train Accuracy = {:.3f}\".format(train_accuracy))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print(\"Test Accuracy = {:.3f}\".format(test_accuracy))\n",
    "        print()\n",
    "    try:\n",
    "        saver\n",
    "    except NameError:\n",
    "        saver = tf.train.Saver()\n",
    "    saver.save(sess,'lenet')\n",
    "    print(\"Model saved\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(validation_accuracy_figure)\n",
    "plt.title(\"Test Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation_accuracy_figure)\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4 - Test a Model on New Images\n",
    "\n",
    "- New images for germany traffic signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "fig, axs = plt.subplots(2,3, figsize=(3, 2))\n",
    "fig.subplots_adjust(hspace = .2, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "\n",
    "my_images = []\n",
    "\n",
    "for i, img in enumerate(glob.glob('/home/nsslab/SDCND/Project3/New_images/*.png')):\n",
    "    image = cv2.imread(img)\n",
    "    axs[i].axis('off')\n",
    "    my_images.append(image)\n",
    "    axs[i].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
